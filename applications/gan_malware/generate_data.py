import os

import numpy as np
import torch
import torchvision.transforms as transforms
from PIL import Image
from torch.autograd import Variable
from torchvision.utils import save_image

from config.config_params_v3 import Opt
from config.config_core import cuda, FloatTensor
from models.info_gan_original import Discriminator
from models.info_gan_original import Generator
from utils import load_image_dataset
from utils.helper import to_categorical, crop


def fix_image(img: Image, output_path: str):
    img_width, img_height = img.size
    if img_width < img_height:
        ratio = int(img_height / img_width)
        box = (0, 0, img_height - img_width * ratio, img_height)
        added_img = img.crop(box)
        added_img_val = np.asarray(added_img)
        img_val = np.asarray(img)
        img_val_final = img_val
        if ratio > 1:
            for _ in range(1, ratio):
                img_val_final = np.concatenate((img_val_final, img_val), axis=1)
        img_val_final = np.concatenate((img_val_final, added_img_val), axis=1)
        merged_img = Image.fromarray(img_val_final)
        # merged_img.show()
        merged_img.save(output_path)
    else:
        img.save(output_path)
        print(f"{output_path} - {img_width}, {img_height}")


def generate_fixed_images():
    print("Only run it after get dataset once")
    PATH_TO_GET_DATA = "../../data/dataset-v2/data"
    folders = os.listdir(PATH_TO_GET_DATA)
    print(folders)

    for folder in folders:
        out_folder = f"../../data/dataset-v2/fixed-data/{folder}"
        os.makedirs(out_folder, exist_ok=True)
        files = os.listdir(f"{PATH_TO_GET_DATA}/{folder}")
        print(files)
        for file in files:
            image = Image.open(f"{PATH_TO_GET_DATA}/{folder}/{file}")
            out_path = f"{out_folder}/{file}"
            fix_image(img=image, output_path=out_path)


def generate_sample_image(n_row, generator, static_label, static_code, latent_dim=None, path=None):
    """Saves a grid of generated digits ranging from 0 to n_classes"""
    # Static sample
    latent_space = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, latent_dim))))
    static_sample = generator(latent_space, static_label, static_code)
    save_image(static_sample.data, path, nrow=n_row, normalize=True)


def generate_fake_data(generator_path, discriminator_path, opt: Opt):
    os.makedirs("../data/dataset-v1.1/fake_data/Stop_0/", exist_ok=True)
    os.makedirs("../data/dataset-v1.1/fake_data/GandCrap_1/", exist_ok=True)
    os.makedirs("../data/dataset-v1.1/fake_data/Nitro_2/", exist_ok=True)
    os.makedirs("../data/dataset-v1.1/generated_data/", exist_ok=True)
    generator_load = Generator(opt=opt)
    discriminator_load = Discriminator(opt=opt)
    if cuda:
        print("We are using GPU for generate fake data")
        generator_load.cuda()
        discriminator_load.cuda()

    generator_load.load_state_dict(torch.load(generator_path))
    generator_load.eval()
    discriminator_load.load_state_dict(torch.load(discriminator_path))
    discriminator_load.eval()

    count_img = 0
    for index in range(50):
        print(index)
        static_label = to_categorical(
            y=np.array([num for _ in range(opt.n_classes) for num in range(opt.n_classes)]),
            num_columns=opt.n_classes,
            FloatTensor=FloatTensor
        )
        static_code = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.code_dim))))
        path_fake_data = f"../data/dataset-v1.1/generated_data/{index}.png"
        generate_sample_image(n_row=opt.n_classes, generator=generator_load, static_label=static_label,
                              static_code=static_code, latent_dim=opt.latent_dim, path=path_fake_data)
        path_output = "../data/dataset-v1.1/fake_data"
        crop(path_input=path_fake_data, path_output=path_output, heightCut=32, widthCut=32, border=2, count=count_img)
        count_img += 1


def generate_real_data_32px(opt: Opt):
    os.makedirs("../data/dataset-v1.1/fake_data/Stop/", exist_ok=True)
    os.makedirs("../data/dataset-v1.1/fake_data/GandCrap/", exist_ok=True)
    os.makedirs("../data/dataset-v1.1/fake_data/Nitro/", exist_ok=True)
    PATH_TO_GET_DATA = "../data/dataset-v1.1/data"
    transform = transforms.Compose(
        [transforms.Resize(opt.img_size_32),
         transforms.CenterCrop(opt.img_size_32),
         transforms.ToTensor(),
         transforms.Grayscale(),
         transforms.Normalize([0.5], [0.5])]
    )

    data_read = load_image_dataset.read_dataset(path=PATH_TO_GET_DATA, transform_info=transform)
    for idx, data in enumerate(data_read):
        print(idx, data)
        if data[1] == 0:
            save_image(data[0], f'../data/dataset-v1.1/fake_data/GandCrap/{idx}.png', normalize=True)
            continue

        if data[1] == 1:
            save_image(data[0], f'../data/dataset-v1.1/fake_data/Nitro/{idx}.png', normalize=True)
            continue

        if data[1] == 2:
            save_image(data[0], f'../data/dataset-v1.1/fake_data/Stop/{idx}.png', normalize=True)
            continue


def generate_real_data_64px(opt: Opt):
    os.makedirs("../data/dataset-v2/fake_data/Stop/", exist_ok=True)
    os.makedirs("../data/dataset-v2/fake_data/GandCrap/", exist_ok=True)
    os.makedirs("../data/dataset-v2/fake_data/Nitro/", exist_ok=True)
    PATH_TO_GET_DATA = "../data/dataset-v2/fixed-data"
    transform = transforms.Compose(
        [transforms.Resize(opt.img_size_64),
         transforms.CenterCrop(opt.img_size_64),
         transforms.ToTensor(),
         transforms.Grayscale(),
         transforms.Normalize([0.5], [0.5])]
    )

    data_read = load_image_dataset.read_dataset(path=PATH_TO_GET_DATA, transform_info=transform)
    for idx, data in enumerate(data_read):
        # print(idx, data)
        label_index = data[1]
        if label_index == 0:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/Babuk_{idx}.png', normalize=True)
        elif label_index == 1:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/Cerber_{idx}.png', normalize=True)
        elif label_index == 2:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/Conti_{idx}.png', normalize=True)
        elif label_index == 3:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/BandCrab_{idx}.png', normalize=True)
        elif label_index == 4:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/Locky-Remove_{idx}.png', normalize=True)
        elif label_index == 5:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/Nitro_{idx}.png', normalize=True)
        elif label_index == 6:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/Ryuk-Remove_{idx}.png', normalize=True)
        elif label_index == 7:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/Stop_{idx}.png', normalize=True)
        elif label_index == 8:
            save_image(data[0], f'../data/dataset-v2/fake_data/Nitro/WannaCry_{idx}.png', normalize=True)


if __name__ == '__main__':
    opt = Opt()
    # generate_fake_data()
    generate_real_data_64px(opt=opt)
    # generate_fixed_images()
