import numpy as np
import wandb
from torch.autograd import Variable

# Classifier
def init_wandb_classifier(name_project, entity, model, opt):
    wandb.init(project=name_project, entity=entity)
    wandb.config = {
        "learning_rate": opt.lr,
        "epochs": opt.n_epochs,
        "batch_size": opt.batch_size
    }

    wandb.watch(model, log="all")

def log_loss_value(type_value, losses_all, accs, dataloader):
    if type_value == "train":
        wandb.log({"loss_train": losses_all.avg})
        wandb.log({"acc_train": 100 * accs / len(dataloader)})
    else:
        wandb.log({"loss_test": losses_all.avg})
        wandb.log({"acc_test": 100 * accs / len(dataloader)})

# GAN
def init_wandb(name_project, entity, generator, discriminator, opt):
    wandb.init(project=name_project, entity=entity)
    wandb.config = {
        "learning_rate": opt.lr,
        "epochs": opt.n_epochs,
        "batch_size": opt.batch_size
    }

    wandb.watch(generator, log="all")
    wandb.watch(discriminator, log="all")


def generate_image(n_row, epoch_index, generator, static_label, static_code, static_z, opt, FloatTensor):
    # Static sample
    latent_space = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))
    static_sample = generator(latent_space, static_label, static_code)
    images = wandb.Image(static_sample.data, caption=f"Ep {epoch_index}")
    wandb.log({"Static sample": images})

    # Get varied c1 and c2
    zeros = np.zeros((n_row ** 2, 1))
    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)
    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))
    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))
    sample1 = generator(static_z, static_label, c1)
    sample2 = generator(static_z, static_label, c2)
    images = wandb.Image(sample1.data, caption=f"Ep {epoch_index}")
    wandb.log({"Varying c1 sample": images})
    images = wandb.Image(sample2.data, caption=f"Ep {epoch_index}")
    wandb.log({"Varying c2 sample": images})


def log_loss_model(d_loss, g_loss, info_loss):
    wandb.log({"D loss": d_loss})
    wandb.log({"G loss": g_loss})
    wandb.log({"info loss": info_loss})
