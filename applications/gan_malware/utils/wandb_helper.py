import numpy as np
import wandb
from torch.autograd import Variable


# Classifier
def init_wandb_classifier(name_project, entity, model, opt):
    wandb.init(project=name_project, entity=entity)
    wandb.config = {
        "learning_rate": opt.lr,
        "epochs": opt.n_epochs,
        "batch_size": opt.batch_size
    }

    wandb.watch(model, log="all")


def log_loss_value(type_value, losses_all, accs, dataloader):
    if type_value == "train":
        wandb.log({"loss_train": losses_all.avg})
        wandb.log({"acc_train": 100 * accs / len(dataloader)})
    else:
        wandb.log({"loss_test": losses_all.avg})
        wandb.log({"acc_test": 100 * accs / len(dataloader)})


# GAN
def init_wandb(name_project, entity, generator, discriminator, opt):
    wandb.init(project=name_project, entity=entity)
    wandb.config = {
        "learning_rate": opt.lr,
        "epochs": opt.n_epochs,
        "batch_size": opt.batch_size
    }

    wandb.watch(generator, log="all")
    wandb.watch(discriminator, log="all")


def generate_image(n_row, epoch_index, generator, static_label, static_code=None, static_z=None, opt=None,
                   FloatTensor=None, unique_dll_vals=None, unique_cs_vals=None, is_only_static=False, is_ac_gan=False):
    # Static sample
    latent_space = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))
    if is_ac_gan == True:
        static_sample = generator(latent_space, static_label)
    else:
        static_sample = generator(latent_space, static_label, static_code)

    images = wandb.Image(static_sample.data, caption=f"Ep {epoch_index}")
    wandb.log({"Static sample": images})

    if is_only_static == False:
        # Get varied c1
        code_dll = np.eye(len(unique_dll_vals[0]))[np.random.choice(unique_dll_vals.shape[0], n_row ** 2)]
        code_cs = np.random.choice(unique_cs_vals, (n_row ** 2, 1))
        c1 = Variable(FloatTensor(np.hstack((code_dll, code_cs))))
        sample1 = generator(static_z, static_label, c1)
        images = wandb.Image(sample1.data, caption=f"Ep {epoch_index}")
        wandb.log({"Varying c1 sample": images})


def old_generate_image(n_row, epoch_index, generator, static_label, static_code, static_z, opt, FloatTensor):
    # Static sample
    latent_space = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))
    static_sample = generator(latent_space, static_label, static_code)
    images = wandb.Image(static_sample.data, caption=f"Ep {epoch_index}")
    wandb.log({"Static sample": images})

    # Get varied c1 and c2
    zeros = np.zeros((n_row ** 2, 1))
    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)
    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))
    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))
    sample1 = generator(static_z, static_label, c1)
    sample2 = generator(static_z, static_label, c2)
    images = wandb.Image(sample1.data, caption=f"Ep {epoch_index}")
    wandb.log({"Varying c1 sample": images})
    images = wandb.Image(sample2.data, caption=f"Ep {epoch_index}")
    wandb.log({"Varying c2 sample": images})


def log_loss_models(d_loss, g_loss, info_loss=None, d_acc=None):
    wandb.log({"D loss": d_loss})
    wandb.log({"G loss": g_loss})
    if info_loss != None:
        wandb.log({"info loss": info_loss})
    if d_acc != None:
        wandb.log({"D accuracy": d_acc})

# def log_trained_value_g_and_d(trained_val_pred, valid, count_index):
#     wandb.log({"trained_data_of_g&d": wandb.plot.line_series(
#         xs=[count_index],
#         ys=[trained_val_pred, valid],
#         keys=["Predicted validity of Discriminator", "Real validity"],
#         title="Trained data after train Generator",
#         xname="x units")})
